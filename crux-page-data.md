# Get CrUX data for a page step by step

## Problem to solve

Google is calculating the Core Web Vital search ranking boost based on CrUX Data:

1. If a page has enough traffic the page CWV is used
2. If the page has not enough data Google is grouping similar page together (see [Google Search Console](https://search.google.com/search-console))
3. If the page group has not enough data Google aggregates the data for whole site

For the prioritization of your optimization work you want to know which URLs have enough CrUX traffic


## Get a list of all page URLs

### Find your sitemap.xml

* Most websites have a sitemap.xml in their root directory. Try to open the sitemap.xml in your browser `https://site-domain.com/sitemap.xml`
* If you are not lucky you might find them linked in the robots.txt file: `https://site-domain.com/robots.txt`
* If you are not lucky, you have to add the URLs manually.


### Extract the URLs from your sitemap.xml

1. Open the sitemap.xml in your browser `https://site-domain.com/sitemap.xml`
![CleanShot 2021-05-23 at 18 33 29](https://user-images.githubusercontent.com/21277749/119269027-e3503c00-bbf5-11eb-85aa-3e40f2255197.png)
2. 
3. 




## Google Sheet

1. Make a copy of the [Google Sheet Template](https://docs.google.com/spreadsheets/d/12ufFf92pErPu5jy_vQmLLCkqjse7Sj894Radw6CTxcw/edit?usp=sharing)
2. Create a free CrUX API Key: 
3. Set the 
4. Get all URL
